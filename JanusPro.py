import sys
import os
import torch
import numpy as np
import folder_paths
import time
import re
from PIL import Image
from transformers import AutoConfig, AutoModelForCausalLM

# å…³é”®è·¯å¾„å¤„ç†ï¼šå°†å½“å‰ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)  # æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„

try:
    from janus.models import MultiModalityCausalLM, VLChatProcessor
    from janus.utils.io import load_pil_images
except ImportError as e:
    print(f"è·¯å¾„è°ƒè¯•ä¿¡æ¯ï¼š")
    print(f"å½“å‰ç›®å½•: {current_dir}")
    print(f"ç›®å½•å†…å®¹: {os.listdir(current_dir)}")
    print(f"sys.path: {sys.path}")
    raise

# æ·»åŠ æ¨¡å‹è·¯å¾„é…ç½®
current_directory = os.path.dirname(os.path.abspath(__file__))
folder_paths.folder_names_and_paths["Janus"] = ([os.path.join(folder_paths.models_dir, "Janus")], folder_paths.supported_pt_extensions)

# è¾…åŠ©å‡½æ•°
def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))

def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

class Janus_ModelLoader:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model_path": ("STRING", {"default": "deepseek-ai/Janus-Pro-7B"}),
            }
        }

    RETURN_TYPES = ("JANUS_MODEL", "PROCESSOR", "TOKENIZER")
    RETURN_NAMES = ("model", "processor", "tokenizer")
    FUNCTION = "load_model"
    CATEGORY = "ğŸ§©Janus"

    def load_model(self, model_path):
        # åŠ è½½é…ç½®
        config = AutoConfig.from_pretrained(model_path)
        language_config = config.language_config
        language_config._attn_implementation = 'eager'

        # åŠ è½½æ¨¡å‹
        vl_gpt = AutoModelForCausalLM.from_pretrained(
            model_path,
            language_config=language_config,
            trust_remote_code=True
        ).to(torch.bfloat16 if torch.cuda.is_available() else torch.float16)
        
        if torch.cuda.is_available():
            vl_gpt = vl_gpt.cuda()

        # åŠ è½½å¤„ç†å™¨
        processor = VLChatProcessor.from_pretrained(model_path)
        tokenizer = processor.tokenizer

        return (vl_gpt, processor, tokenizer)

class Janus_MultimodalUnderstanding:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("JANUS_MODEL",),
                "processor": ("PROCESSOR",),
                "tokenizer": ("TOKENIZER",),
                "image": ("IMAGE",),
                "question": ("STRING", {"default": "describe the image", "multiline": True}),
                "seed": ("INT", {"default": 42, "min": 0, "max": 0xffffffffffffffff}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.05}),
                "temperature": ("FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.05}),
            },
            "optional": {
                "max_new_tokens": ("INT", {"default": 512, "min": 16, "max": 2048}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("response",)
    FUNCTION = "understand"
    CATEGORY = "ğŸ§©Janus"

    def understand(self, model, processor, tokenizer, image, question, seed, top_p, temperature, max_new_tokens=512):
        # ä¿®å¤ç§å­èŒƒå›´é—®é¢˜
        seed = seed % (2**32)
        
        # è®¾ç½®éšæœºç§å­ï¼ˆæ·»åŠ CUDAåŒæ­¥ï¼‰
        torch.manual_seed(seed)
        np.random.seed(seed % (2**32 - 1))  # é€‚é…numpyç§å­èŒƒå›´
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
            torch.cuda.synchronize()

        try:
            # å›¾åƒé¢„å¤„ç†ï¼ˆæ·»åŠ ç»´åº¦éªŒè¯ï¼‰
            if isinstance(image, list):
                image_tensor = image[0]
            else:
                image_tensor = image
                
            pil_image = tensor2pil(image_tensor)
            if pil_image.mode != "RGB":
                pil_image = pil_image.convert("RGB")

            # æ„å»ºå¯¹è¯ï¼ˆæ·»åŠ å¼‚å¸¸å¤„ç†ï¼‰
            try:
                conversation = [{
                    "role": "<|User|>",
                    "content": f"<image_placeholder>\n{question}",
                    "images": [pil_image],
                }, {
                    "role": "<|Assistant|>", 
                    "content": ""
                }]
            except Exception as e:
                print(f"å¯¹è¯æ„å»ºå¤±è´¥: {e}")
                return ("Error: Invalid conversation format",)

            # å¤„ç†è¾“å…¥ï¼ˆæ·»åŠ ç»´åº¦è°ƒè¯•ï¼‰
            try:
                prepare_inputs = processor(
                    conversations=conversation,
                    images=[pil_image],
                    force_batchify=True
                ).to(model.device, dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16)
                
                print(f"è¾“å…¥å¼ é‡å½¢çŠ¶ - input_ids: {prepare_inputs.input_ids.shape}")
                print(f"æ³¨æ„åŠ›æ©ç å½¢çŠ¶: {prepare_inputs.attention_mask.shape}")
            except Exception as e:
                print(f"è¾“å…¥å¤„ç†å¤±è´¥: {e}")
                return ("Error: Input processing failed",)

            # ç”Ÿæˆè¿‡ç¨‹ï¼ˆæ·»åŠ å‚æ•°éªŒè¯ï¼‰
            try:
                inputs_embeds = model.prepare_inputs_embeds(**prepare_inputs)
                print(f"è¾“å…¥åµŒå…¥å½¢çŠ¶: {inputs_embeds.shape}")

                generation_config = {
                    "inputs_embeds": inputs_embeds,
                    "attention_mask": prepare_inputs.attention_mask,
                    "pad_token_id": tokenizer.eos_token_id,
                    "bos_token_id": tokenizer.bos_token_id,
                    "eos_token_id": tokenizer.eos_token_id,
                    "max_new_tokens": max_new_tokens,
                    "do_sample": temperature > 0,
                    "temperature": temperature if temperature > 0 else 1.0,
                    "top_p": top_p,
                }

                # æ‰§è¡Œç”Ÿæˆï¼ˆæ·»åŠ æ—¶é—´ç›‘æ§ï¼‰
                start_time = time.time()
                outputs = model.language_model.generate(**generation_config)
                print(f"ç”Ÿæˆè€—æ—¶: {time.time() - start_time:.2f}ç§’")

            except Exception as e:
                print(f"ç”Ÿæˆå¤±è´¥: {e}")
                return ("Error: Generation failed",)

            # è§£ç è¾“å‡ºï¼ˆæ·»åŠ å¼‚å¸¸å¤„ç†ï¼‰
            try:
                full_output = outputs[0].cpu().tolist()
                answer = tokenizer.decode(full_output, skip_special_tokens=True)
                
                # æ¸…ç†ç‰¹æ®Šæ ‡è®°
                clean_pattern = r'<\|.*?\|>'
                clean_answer = re.sub(clean_pattern, '', answer).strip()
                
                return (clean_answer,)
                
            except Exception as e:
                print(f"è§£ç å¤±è´¥: {e}")
                return ("Error: Output decoding failed",)

        except Exception as e:
            print(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°æœªæ•è·çš„å¼‚å¸¸: {e}")
            return ("Error: Unexpected processing error",)


class Janus_ImageGeneration:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("JANUS_MODEL",),
                "processor": ("PROCESSOR",),
                "tokenizer": ("TOKENIZER",),
                "prompt": ("STRING", {"multiline": True, "default": "Master shifu racoon wearing drip attire"}),
                "seed": ("INT", {"default": 12345, "min": 0, "max": 0xffffffffffffffff}),
                "cfg_weight": ("FLOAT", {"default": 5.0, "min": 1.0, "max": 10.0, "step": 0.5}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ§©Janus"

    def generate(self, model, processor, tokenizer, prompt, seed, cfg_weight, temperature):
        # æ¸…ç†ç¼“å­˜å¹¶è®¾ç½®ç§å­
        torch.cuda.empty_cache()
        seed = seed % (2**32)
        torch.manual_seed(seed)
        np.random.seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

        # å›ºå®šå‚æ•°ï¼ˆä¸åŸå§‹ä»£ç ä¸€è‡´ï¼‰
        width = 384
        height = 384
        parallel_size = 5
        patch_size = 16
        image_token_num = 576

        # æ„å»ºè¾“å…¥æ–‡æœ¬
        messages = [{'role': '<|User|>', 'content': prompt},
                   {'role': '<|Assistant|>', 'content': ''}]
        text = processor.apply_sft_template_for_multi_turn_prompts(
            conversations=messages,
            sft_format=processor.sft_format,
            system_prompt=''
        ) + processor.image_start_tag

        # ç”Ÿæˆè¾“å…¥ID
        input_ids = torch.LongTensor(tokenizer.encode(text)).to(model.device)

        # åˆå§‹åŒ–Tokensï¼ˆä¸¥æ ¼ä¿æŒåŸå§‹ç»“æ„ï¼‰
        tokens = torch.zeros((parallel_size * 2, len(input_ids)), dtype=torch.int, device=model.device)
        for i in range(parallel_size * 2):
            tokens[i, :] = input_ids
            if i % 2 != 0:
                tokens[i, 1:-1] = processor.pad_id

        # ç”Ÿæˆè¿‡ç¨‹ï¼ˆä¿æŒåŸå§‹å¾ªç¯ç»“æ„ï¼‰
        inputs_embeds = model.language_model.get_input_embeddings()(tokens)
        generated_tokens = torch.zeros((parallel_size, image_token_num), dtype=torch.int, device=model.device)
        
        pkv = None
        for i in range(image_token_num):
            with torch.no_grad():
                outputs = model.language_model.model(
                    inputs_embeds=inputs_embeds,
                    use_cache=True,
                    past_key_values=pkv
                )
                pkv = outputs.past_key_values
                
                # åŸå§‹åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼å®ç°
                logits = model.gen_head(outputs.last_hidden_state[:, -1, :])
                logit_cond = logits[0::2, :]
                logit_uncond = logits[1::2, :]
                logits = logit_uncond + cfg_weight * (logit_cond - logit_uncond)
                
                # é‡‡æ ·é€»è¾‘
                probs = torch.softmax(logits / temperature, dim=-1)
                next_token = torch.multinomial(probs, num_samples=1)
                generated_tokens[:, i] = next_token.squeeze(dim=-1)
                
                # å‡†å¤‡ä¸‹ä¸€è½®è¾“å…¥ï¼ˆä¿æŒåŸå§‹è§†å›¾æ“ä½œï¼‰
                next_token = torch.cat([next_token.unsqueeze(1), next_token.unsqueeze(1)], dim=1).view(-1)
                img_embeds = model.prepare_gen_img_embeds(next_token)
                inputs_embeds = img_embeds.unsqueeze(dim=1)

        # å›¾åƒè§£ç ï¼ˆä¸¥æ ¼ä¿æŒåŸå§‹å®ç°ï¼‰
        patches = model.gen_vision_model.decode_code(
            generated_tokens.to(dtype=torch.int),
            shape=[parallel_size, 8, width//patch_size, height//patch_size]
        )
        
        # åå¤„ç†ï¼ˆåŸå§‹unpacké€»è¾‘ï¼‰
        dec = patches.to(torch.float32).cpu().numpy().transpose(0, 2, 3, 1)
        dec = np.clip((dec + 1) / 2 * 255, 0, 255).astype(np.uint8)
        visual_img = np.zeros((parallel_size, width, height, 3), dtype=np.uint8)
        visual_img[:, :, :] = dec

        # è½¬æ¢ä¸ºComfyUIå›¾åƒæ ¼å¼
        output_images = []
        for i in range(parallel_size):
            pil_img = Image.fromarray(visual_img[i]).resize((768, 768), Image.LANCZOS)
            output_images.append(pil2tensor(pil_img))
        
        return (torch.cat(output_images, dim=0),)


NODE_CLASS_MAPPINGS = {
    "Janus_ModelLoader": Janus_ModelLoader,
    "Janus_MultimodalUnderstanding": Janus_MultimodalUnderstanding,
    "Janus_ImageGeneration": Janus_ImageGeneration
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Janus_ModelLoader": "ğŸ§©Janus Model Loader",
    "Janus_MultimodalUnderstanding": "ğŸ§©Janus Multimodal Understanding",
    "Janus_ImageGeneration": "ğŸ§©Janus Image Generation"
}
